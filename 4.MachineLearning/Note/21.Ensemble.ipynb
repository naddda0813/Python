{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "- 여러개의 분류모델을 조합해서 더 나은 성능을 내는 방법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "- 의사결정트리 bagging(단일 모델 조합)에서 예측을 실행하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  datasets\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손글씨 데이터 가져오기\n",
    "mnist = datasets.load_digits()\n",
    "features, labels = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사결정 나무를 이용한 교차검증 10번 실시\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8280229671011794, 0.8235630043451273, 0.8224674115456239, 0.8235692116697703, 0.8341464928615766, 0.8185692116697704, 0.8241247672253259, 0.8180136561142148, 0.8235630043451272, 0.8258038485412786]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_scores = []\n",
    "# 10번을 실행하여 교차검증 10번씩 실행 \n",
    "for i in range(10):\n",
    "    scores = cross_val_score(\n",
    "        # 모델 적용 \n",
    "        tree.DecisionTreeClassifier(),\n",
    "        features,\n",
    "        labels,\n",
    "        cv=10,\n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "    cv_scores.append(scores.mean())\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8258038485412786, 0.8258038485412786, 0.8258038485412786, 0.8258038485412786, 0.8258038485412786, 0.8258038485412786, 0.8258038485412786, 0.8258038485412786, 0.8258038485412786, 0.8258038485412786]\n"
     ]
    }
   ],
   "source": [
    "# RandomForest를 이용한  교차검증 10번\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    score = cross_val_score(\n",
    "        RandomForestClassifier(),\n",
    "        features,\n",
    "        labels,\n",
    "        cv=10,\n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "print(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 함수 만들기 \n",
    " def cross_validation(classifier,features,labels):\n",
    "    cv_scores = []\n",
    "    for i in range(10):\n",
    "        score = cross_val_score(\n",
    "        classifier,\n",
    "        features,\n",
    "        labels,\n",
    "        cv=10,\n",
    "        scoring=\"accuracy\"\n",
    "        )\n",
    "        cv_scores.append(scores.mean())\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정 나무 \n",
    "dt_cv_scores = cross_validation(tree.DecisionTreeClassifier(),features,labels)\n",
    "dt_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786,\n",
       " 0.8258038485412786]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForest\n",
    "rf_cv_scores = cross_validation(RandomForestClassifier(),features,labels)\n",
    "rf_cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤포레스트와 의사결정나무의 정확도의 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv_list={'randrom_forest':rf_cv_scores,\"decision_tree\":dt_cv_scores}\n",
    "df = pd.DataFrame(cv_list)\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 보팅(voting) 앙상블\n",
    "- 단일 모델을 앙상블하여 더 나은 예측을 하는 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 모델 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-tree :  0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "# 의사결정나무 \n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "dtree_score = dtree.score(X_test, y_test)\n",
    "print(\"d-tree : \", dtree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn :  0.975\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(\"Knn : \",  knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM :  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "#학습\n",
    "svm = SVC(probability=True).fit(X_train, y_train)\n",
    "svm_score = svm.score(X_test, y_test)\n",
    "print(\"SVM : \",svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하드 보팅\n",
    "- 각각의 분류모델의 예측값들을 모아, 가장 많은 득표를  받은 예측값으로 최종 결론을 내는 방식\n",
    "- 점수로 매김(다수결)\n",
    "- A 모델은 ㄱ, B 모델은 ㄴ, C 모델은 ㄱ이라 할때 ㄱ을 채택 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../Data/Hardvoting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805555555555555"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# 학습\n",
    "voting_clf = VotingClassifier(\n",
    "    # 평가방법 \n",
    "    # 위에서 만든 매개변수 \n",
    "    estimators =[('decision_tree',dtree),('knn',knn),('svm',svm)],\n",
    "    # 정확도가 높은 걸 비중을 높여 정확도를 높인다 \n",
    "    # 기울기\n",
    "    weights = [0.5,1,1],\n",
    "    voting = \"hard\"\n",
    ").fit(X_train,y_train)\n",
    "# 정확도\n",
    "voting_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소프트 보팅\n",
    "- 각각의 분류모델을 활용하여 모든 분류값들의 확률들을 더해서 가장 높은 점수를 획득한 분류값으로 최종결론을 내는 방식입니다.\n",
    "- 맞는 확률\n",
    "- A 모델은 {ㄱ: 0.7, ㄴ:0.3}, B 모델은 {ㄱ:0.4, ㄴ:0.6 }, C 모델으 {ㄱ:0.6,ㄴ:0.4}로 예측했을 때 \n",
    "- ㄱ은 (0.7+0.4+0.6)/3 = 0.56\n",
    "- ㄴ은 (0.3 +0.6 +0.4)/3 = 0.43\n",
    "로 ㄱ 채택 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../Data/softvoting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805555555555555"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# 학습\n",
    "voting_clf = VotingClassifier(\n",
    "    # 평가방법 \n",
    "    # 위에서 만든 매개변수 \n",
    "    estimators =[('decision_tree',dtree),('knn',knn),('svm',svm)],\n",
    "    # 정확도가 높은 걸 비중을 높여 정확도를 높인다 \n",
    "    # 기울기\n",
    "    weights = [0.5,1,1],\n",
    "    voting = \"soft\"\n",
    ").fit(X_train,y_train)\n",
    "# 정확도\n",
    "voting_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c34e8390e776d2ee205b71ed5a6130fee3cef8da5e87e926ce18e14f4a070d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
